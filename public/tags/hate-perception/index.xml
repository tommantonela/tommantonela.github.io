<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hate Perception | Antonela Tommasel</title>
    <link>/tags/hate-perception/</link>
      <atom:link href="/tags/hate-perception/index.xml" rel="self" type="application/rss+xml" />
    <description>Hate Perception</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 27 Sep 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Hate Perception</title>
      <link>/tags/hate-perception/</link>
    </image>
    
    <item>
      <title>Hate Speech Bias</title>
      <link>/project/hate-beholder/</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/project/hate-beholder/</guid>
      <description>&lt;div style=&#34;text-align: justify&#34;&gt;
&lt;p&gt;Awarded by Facebook as part of the 
&lt;a href=&#34;https://research.fb.com/programs/research-awards/proposals/content-policy-research-on-social-media-platforms-request-for-proposals/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Content Policy Research on Social Media Platforms request for proposals&amp;rdquo;&lt;/a&gt;
.&lt;/p&gt;
&lt;p&gt;PI: Antonela Tommasel&lt;/p&gt;
&lt;p&gt;Collaborators (in alphabetical order):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Daniela Godoy - ISISTAN, CONICET-UNICEN, Argentina&lt;/li&gt;
&lt;li&gt;Aiqi Jiang - Queen Mary University of London, UK&lt;/li&gt;
&lt;li&gt;Arkaitz Zubiaga - Queen Mary University of London, UK&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An important goal for hate speech detection techniques is to ensure that they are not unduly biased towards or against
particular norms of offence. Training data is usually obtained by manually annotating a set of texts. Thereby, the reliability
of human annotations is essential. Meanwhile, the ability to let big data &amp;ldquo;speak for itself&amp;rdquo; has been questioned as its
representativeness, spatiotemporal extent and uneven demographic information can make it subjective. We hypothesize
that demographics substantially affect hate speech perception. In this context, the research question guiding this project is:&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align: center&#34;&gt;
&lt;em&gt;How do latent norms and biases caused by demographics derive in biased datasets, which affects the performance of hate speech detection systems?&lt;/em&gt;
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>
