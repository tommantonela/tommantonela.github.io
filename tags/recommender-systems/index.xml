<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Recommender Systems | Antonela Tommasel</title>
    <link>https://tommantonela.github.io/tags/recommender-systems/</link>
      <atom:link href="https://tommantonela.github.io/tags/recommender-systems/index.xml" rel="self" type="application/rss+xml" />
    <description>Recommender Systems</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 05 Jul 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Recommender Systems</title>
      <link>https://tommantonela.github.io/tags/recommender-systems/</link>
    </image>
    
    <item>
      <title>Havenâ€™t I just Listened to This?: Exploring Diversity in Music Recommendations</title>
      <link>https://tommantonela.github.io/publication/2022umapb/</link>
      <pubDate>Tue, 05 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://tommantonela.github.io/publication/2022umapb/</guid>
      <description></description>
    </item>
    
    <item>
      <title>I Want to Break Free! Recommending Friends from Outside the Echo Chamber</title>
      <link>https://tommantonela.github.io/publication/2021recsysb/</link>
      <pubDate>Sat, 25 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://tommantonela.github.io/publication/2021recsysb/</guid>
      <description></description>
    </item>
    
    <item>
      <title>OHARS: Second Workshop on Online Misinformation- and Harm-Aware Recommender Systems</title>
      <link>https://tommantonela.github.io/publication/2021recsysa/</link>
      <pubDate>Sat, 25 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://tommantonela.github.io/publication/2021recsysa/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Influence and performance of user similarity metrics in followee prediction</title>
      <link>https://tommantonela.github.io/publication/2020jis/</link>
      <pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://tommantonela.github.io/publication/2020jis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Workshop on Online Misinformation- and Harm-Aware Recommender Systems</title>
      <link>https://tommantonela.github.io/publication/2020recsys/</link>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://tommantonela.github.io/publication/2020recsys/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Surviving to social media in the misinformation era </title>
      <link>https://tommantonela.github.io/talk/wids_lapaz2020/</link>
      <pubDate>Sat, 13 Jun 2020 14:00:00 +0000</pubDate>
      <guid>https://tommantonela.github.io/talk/wids_lapaz2020/</guid>
      <description>&lt;h3 id=&#34;abstract-&#34;&gt;Abstract&lt;/h3&gt;
&lt;div style=&#34;text-align: justify&#34;&gt;
&lt;p&gt;Social media has become the primary source of news for their users by enriching the life and activities of its users, thus giving rise to new forms of communication and interaction. Besides fostering social connections between their users, social media also represents the ideal environment for undesirable phenomena, such as the dissemination of unwanted or aggressive content, misinformation and fake news, which affect the individuals as well as the society as a whole. Thereby, in the last few years, the research on misinformation has received increasing attention. The unlimited possibilities offered by social media sites generate new problems related to information overload, the quality of published information and the formation of new social relationships. This opens the possibility to the contamination of social media with unwanted and unreliable content (false news, rumours, spam, hoaxes), which influences the perception and understanding of events, exposing users to risks. Motivated by the large amount of heterogeneous information available on social media and considering the consequences of the exposure to unwanted and unreliable content, the existence of accounts dedicated to sharing said content, and the rapid dispersion of both phenomena, in this talk we will explore the current actions that are being taken, and how simple processes as recommendations can affect misinformation diffusion. Then, we will focus on what is left to do and can we do to make social media a safer environment.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Friends or Foe: Recommending friends in the misinformation era</title>
      <link>https://tommantonela.github.io/talk/roma2019/</link>
      <pubDate>Thu, 06 Jun 2019 14:00:00 +0000</pubDate>
      <guid>https://tommantonela.github.io/talk/roma2019/</guid>
      <description>&lt;h3 id=&#34;abstract-&#34;&gt;Abstract&lt;/h3&gt;
&lt;div style=&#34;text-align: justify&#34;&gt;
&lt;p&gt;Social media has become the primary source of news for their users by enriching the life and activities of its users, thus giving rise to new forms of communication and interaction. Besides fostering social connections between their users, social media also represents the ideal environment for undesirable phenomena, such as the dissemination of unwanted or aggressive content, misinformation and fake news, which affect the individuals as well as the society as a whole. Thereby, in the last few years, the research on misinformation has received increasing attention. The unlimited possibilities offered by social media sites generate new problems related to information overload, the quality of published information and the formation of new social relationships. This opens the possibility to the contamination of social media with unwanted and unreliable content (false news, rumours, spam, hoaxes), which influences the perception and understanding of events, exposing users to risks. Motivated by the large amount of heterogeneous information available on the social Web and considering the consequences of the exposure to unwanted and unreliable content on social media, the existence of accounts dedicated to sharing said content, and the rapid dispersion of both phenomena, the goal of this work in progress is the provision of reliable recommendation systems based on the integration of techniques that automatically allow the detection of unreliable content and the users publishing it. Thereby, in this talk we will explore the concept of user trustworthiness to avoid making &amp;ldquo;bad&amp;rdquo; recommendations that could favour the propagation of unreliable content and polluting users. Then, we will focus on how could we model the behaviour of users and their social groups in the context of the information diffusion process. Finally, we will talk about the planned actions and research milestones.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Personalized architectural documentation based on stakeholdersâ€™ information needs</title>
      <link>https://tommantonela.github.io/publication/2014jserd/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://tommantonela.github.io/publication/2014jserd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>OHARS</title>
      <link>https://tommantonela.github.io/project/royal-society/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://tommantonela.github.io/project/royal-society/</guid>
      <description>&lt;div style=&#34;text-align: justify&#34;&gt;
&lt;p&gt;Awarded as part of the Bilateral Collaboration Projects between CONICET &amp;amp; Royal Society.&lt;/p&gt;
&lt;p&gt;PIs: Daniela Godoy &amp;amp; Arkaitz Zubiaga&lt;/p&gt;
&lt;p&gt;Collaborators (in alphabetical order):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rabab Alkhalifa&lt;/li&gt;
&lt;li&gt;Aiqi Jiang&lt;/li&gt;
&lt;li&gt;Matthew Purver&lt;/li&gt;
&lt;li&gt;Juan Manuel Rodriguez&lt;/li&gt;
&lt;li&gt;Silvia Schiaffino&lt;/li&gt;
&lt;li&gt;Antonela Tommasel&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is common for online social media platforms to recommend content to its users through features such as
“whom to follow” or personalised content. It has been shown however that social media platforms also spread
harmful contents that have proven problematic. This project aims to detect and mitigate content flagged as
online harm, which includes hate speech and misinformation. These problematic issues in social media have
led to mental health issues owing to hate speech messages, as well as a disruption of the democratic system
due to the diffusion of misinformation. Identification of harmful content online has however proven difficult, with
not only the scientific community but also social media platforms and governments worldwide calling for
support to develop effective methods.&lt;/p&gt;
&lt;p&gt;This project aims to develop novel recommendation algorithms for social media that prevent the
amplification of online harms including misinformation and hate speech. Sources that are likely to generate
this sort of online harm will be identified and will be flagged prior to making decisions with the
recommender system. The algorithms will need to consider three main aspects: (1) detection of
misinformation and abusive language from a multilingual perspective, for English and Spanish (2)
incorporation of the notion of content toxicity, and accounts that promote it, into the inner components of
recommendation algorithms (3) definition of mechanisms to counteract user exposure to online harm, such
as the addition of features (such as provenance and context of information) that will increase
user-awareness and help foster an informed decision making. The algorithms will also need to prevent
potential biases inherent to traditional recommender systems, such as popularity and homogeneity.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>
